TEST SPECIFIC INFO

mergesort :: classical recursive mergesort, division in halves
    |__ threshold :: here is a negative number denoting the depth in the division tree
umergesort :: unbalanced mergesort, division in two parts with a user-defined ratio
    |__ threshold :: here is a positive number denoting the size
    |__ ratio=int:int :: as explained above
pmergesort :: mergesort with parallelised merge
    |__ threshold :: there are 3 thresholds to be defined here:
                     1 - the same as for mergesort
                     2 - the minimum size we want for dividing the merge process
                     3 - the minimum size we want for dividing the copy process
                     If you want, you can specify only the first with threshold=t1; otherwise
                     you can specify them with a list, ex. [t1] or [t1,t2] or [t1,t2,t3];
                     as usual, if you want to loop over many of them, write down a list of lists,
                     ex. [[t11,t12,t13],[t21,t22],[t31,t32,t33],[t41]]; range operator  ..  is not
                     defined and for simplicity all elements of the list must be of the same type,
                     so if you write [[t11,t12,t13],[t21,t22],[t31,t32,t33],t41] then t41 will not
                     be recognised                     
quicksort :: classical recursive quicksort, elements equal to pivot are kept together in division
    |__ threshold :: here again is a positive number denoting the size


RANGES

Various options can be specified with a list of values, specified with square brackets [ ];
there are two kinds of separator, 
, :: to indicate a list
.. :: to indicate a range (at the moment not implemented for strings)
      when .. is preceded by , the range is calculated with the same step between the preceding two
      values
Usually a list of values means that the test will be repeated for all such values.
WARNING: strings cannot begin with a number!!!

OPTIONS DETAILS

threads=int
threads=[ints] :: specify number of threads - that is number of workers; 0 will give you purely
                  sequential execution, without any overhead of the parallel implementation
input=int
input=[ints] :: specify the desired dimensions of input; input will be randomly generated and saved
                respective files for later inspection
input=filename
input=[filenames] :: specify desired input files; they will be processed with std::cin, so use
                     recognized separators such as space or newline
chrono :: activate the high_resolution_clock of C++ std to measure execution time of the parallel
          process only (works even for the sequential execution, threads=0)
result :: save results in distinct files; wheir names will be automatically generated by removing
          everything after the first . in the input filename and adding the suffix output
result=filename :: save all results in the same specified file
log=[loggables] :: activate a separate thread, interacting with the user during the execution via
        |          std::cin; when reading 1 it will print the recorded loggables in the specified
        |          log.file; when reading any other value it will terminate
        |__ jobSummary :: number of completed, distributable, waiting jobs per worker
        |__ jobDependency :: which jobs is a given job waiting for
        |__ jobReceiving :: log when a worker is receiving a job
        |__ jobDoing :: log when a job is being done by a worker
        |__ jobDistributing :: log when a job is in the distribution process
        |__ jobCompleted :: log when a job is completed
        |__ jobSummaryForQueueMoves :: log job summary when there is a move in the queue of
        |                              available workers
        |__ queueMoves :: log all moves in the queue of available workers
        |__ queueFull :: log when the queue is seen complete; remember that we are in relaxed memory
        |                order plus acquire/release sync, so this doesn't mean that all workers are 
        |                available, that is idle!
        |__ workerAvailable :: log when a worker is available for new jobs, that is idle
log.file=filename :: specify the logger filename
log.dim=int :: specify the size of the ring buffer in which loggables are recorded during execution
report=[reportables] :: activate the report after processing completion of the specified recordables
            |           the record will be saved in csv format for later processing
            |__ threads :: number of threads
            |__ size :: size of the input
            |__ threshold :: specified granularity (actually the value of threshold by now)
            |__ chrono :: recorded time of execution
            |__ parameters :: test specific parameters, by now unused... 
                              it could be used in umergesort
report.file=filename :: specify where the report will be saved


NOTES OF THE AUTHOR

I have written this framework with the idea of testing a different idea of scheduler (not strictly 
greedy) with minimal synchronization, so:
1- certain choices will look absurd, like keeping all completed jobs: I tried to keep everything
   of the process scheduling evident even during execution, so function with branches are just split
   in different jobs
2- the framework is rudimentary, many improvements would be need for serious use, like memory 
   management, possibility to recycle each job, exception management...
3- as you'll notice, most of the code is due to the intention to study the process itself...
4- the framework is not energy efficient: my secondary purpose was to test the relaxed memory and I
   decided to use only active waitings
Nevertheless I left some possible choices at code level, i.e. if you want to play with settings of 
the scheduler, such as "DFS_TO_ME_BFS_TO_YOU", you will have to change the code and recompile.

If after all that I will find out that there is interest, I could consider rewriting everything with
a different purpose in mind. Otherwise I will keep to use the already existing frameworks :)


LICENSE AND CONTACT INFO

contact the author: Michele Miccinesi 
                    moc.liamg@iseniccim.elehcim
                    
I will be grateful for any comment and suggestion.
